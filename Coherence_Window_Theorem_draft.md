# The Coherence Window Theorem: Formalizing d = 2 for Intensional Type Theory

## 1. What We Need to Prove and Why

The PEN framework treats the "coherence window" d as a parameter of the model. For the Genesis Sequence to be a *consequence* of intensional type theory rather than an artifact of a modeling choice, we need:

**Main Theorem (Informal).** When a new structure is introduced into a library built on intensional type theory (HoTT/Cubical TT), the irreducible coherence obligations it generates reference at most the two most recent layers of the library. Moreover, this bound is tight: there exist structures whose obligations genuinely span two layers.

**Contrast Theorem (Informal).** In extensional type theory (MLTT+UIP, or equivalently in a set-level foundation like ZFC), the analogous obligations reference at most one layer.

The remainder of this document makes these statements precise.

---

## 2. The Key Idea in Plain Language

Before the formalism, here is the intuition in one paragraph:

In extensional type theory, equality is a *property* — either two things are equal or they aren't, and there's at most one proof. So when you introduce a new structure, you check that it's well-formed (does it type-check against the current library?), and you're done. The *checking* doesn't generate further obligations, because there's nothing to check about the checks.

In intensional type theory, equality is *structure* — a path, which is itself a mathematical object with its own paths. So when you introduce a new structure, you must provide compatibility *data* (paths witnessing that your structure respects existing structure). But then this compatibility data must itself be coherent — the paths you provided must be compatible with each other (homotopies witnessing that your paths compose correctly). This second layer of obligation is genuinely new. However — and this is the crux — a *third* layer (homotopies between homotopies witnessing that your homotopies compose correctly) is *not* independently required. It is determined by the first two layers, by a generalization of Mac Lane's coherence theorem.

Two layers of independent obligation. Not one, not three. This is why d = 2.

---

## 3. Formal Setup

### 3.1 The Library as a CW-Complex Presentation

We work in HoTT (or Cubical Type Theory — the distinction won't matter for this argument).

**Definition 3.1 (Cell Presentation).** A *cell presentation* P = (C₀, C₁, C₂, ...) of a type X consists of:
- C₀: a set of 0-cells (point constructors)
- C₁: a set of 1-cells (path constructors), where each c ∈ C₁ has source and target in the free ∞-groupoid generated by C₀
- C₂: a set of 2-cells (surface constructors), where each c ∈ C₂ has source and target in the free ∞-groupoid generated by C₀ ∪ C₁
- And so on.

Every Higher Inductive Type in HoTT is specified by such a presentation. For example:
- **The circle S¹:** C₀ = {base}, C₁ = {loop : base = base}, C_n = ∅ for n ≥ 2.
- **The sphere S²:** C₀ = {base}, C₁ = ∅, C₂ = {surf : refl_base = refl_base}, C_n = ∅ for n ≥ 3.
- **The torus T²:** C₀ = {base}, C₁ = {p : base = base, q : base = base}, C₂ = {surf : p · q = q · p}.

**Definition 3.2 (Library State).** A *library state* B_n at step n is a sequence of cell presentations (P₁, P₂, ..., P_n), where each P_i was introduced at step i. The *realized types* are the HITs (or other type formers) corresponding to these presentations.

**Definition 3.3 (Layer).** The *layer* L_k is the set of cells introduced at step k, together with the derived structure they generate (elimination principles, computation rules, and their consequences at bounded depth). Formally:

    L_k := Cells(P_k) ∪ Elim(P_k, B_{k-1})

where Elim(P_k, B_{k-1}) denotes the elimination principle of P_k over the types in B_{k-1}, together with its computation rules.

### 3.2 Coherence Obligations

This is the central definition. When we "seal" a new structure against the library, we must show that its elimination principle is well-defined — that the data we provide for each constructor is *coherent*. The question is: how deep into the library's history does this coherence need to reach?

**Definition 3.4 (Elimination Data).** Given a HIT X with cell presentation P = (C₀, C₁, C₂, ...) and a type family Y : X → U, *elimination data* for the pair (X, Y) consists of:
- For each 0-cell c ∈ C₀: a point d_c : Y(c)
- For each 1-cell p ∈ C₁ with p : a = b: a path d_p : transport(p, d_a) = d_b
- For each 2-cell s ∈ C₂: a homotopy d_s witnessing coherence of the relevant path data
- And so on for higher cells.

**Definition 3.5 (Coherence Obligation).** A *coherence obligation* for elimination data (d_c, d_p, d_s, ...) at dimension k is a condition of the form:

> The k-dimensional elimination datum d must satisfy an equation whose terms involve elimination data of dimension < k and library structure from specific layers.

An obligation is *irreducible at layer depth j* if its statement essentially involves structure from L_{n-j} (the layer introduced j steps before the current one) and cannot be reformulated using only structure from more recent layers.

**Definition 3.6 (Coherence Window).** The *coherence window* of a type-theoretic foundation is the smallest d ∈ ℕ such that for every cell presentation P introduced at step n+1, every irreducible coherence obligation for the elimination data of P references only layers L_n, L_{n-1}, ..., L_{n-d+1}.

Equivalently: obligations of depth > d are either absent or reducible to obligations of depth ≤ d.

### 3.3 Stabilization

**Definition 3.7 (Obligation Stabilization).** Let O^(k)(P, B_n) denote the set of irreducible coherence obligations generated when presentation P is sealed against a library of depth k (i.e., considering only the last k layers). The obligations *stabilize at depth d* if for all k ≥ d:

    O^(k)(P, B_n) ≅ O^(d)(P, B_n)

where ≅ denotes isomorphism of obligation sets (same number, same dimensional types, same structural dependencies).

---

## 4. The Main Theorems

### Theorem A (Extensional Window = 1)

**Theorem.** In MLTT + UIP (or any type theory where the identity type is an h-proposition), the coherence window is d = 1.

**Proof.**

Step 1: In MLTT+UIP, every type is an h-set. This means that for any a, b : A, the type (a =_A b) is either empty or contractible.

Step 2: Consider introducing a new structure P at step n+1. The elimination data for P consists of:
- Point data: for each constructor c, a point d_c in the target type
- Path data: for each path constructor p, a path d_p in the target type

But in an h-set target, the path d_p (if it exists) is *unique* — because the identity type of an h-set is a proposition. So the path data is either impossible (the equation has no solution) or forced (there's exactly one solution).

Step 3: Since the path data is forced, there are no *independent choices* to be made about how the path data interacts with previously existing path data. The path coherence condition — "do my paths compose correctly with the library's paths?" — is a proposition, not data. It either holds or it doesn't.

Step 4: Therefore, the obligations generated at step n+1 are:
- Check well-formedness of point data against L_n (the current layer). **This is a depth-1 obligation.**
- Check that the forced path data is consistent. This is a proposition that can be checked using only L_n. **Also depth 1.**

No reference to L_{n-1} or earlier layers is needed: once the point data is compatible with L_n, the (unique) path data is automatically compatible with everything.

Step 5: The bound is tight: we do need L_n (the immediately preceding layer), because the new structure's constructors interact with the types defined at step n. ∎

**Remark.** This proof applies equally to ZFC (where all "types" are sets and there's no identity type with independent structure) and to any set-level foundation.

---

### Theorem B (Intensional Window = 2)

**Theorem.** In HoTT (or Cubical Type Theory), the coherence window is d = 2.

This theorem has two parts: an upper bound (d ≤ 2) and a lower bound (d ≥ 2).

#### Part 1: Upper Bound (d ≤ 2)

**Theorem B.1.** For any cell presentation P introduced at step n+1, the irreducible coherence obligations for its elimination data reference at most layers L_n and L_{n-1}.

**Proof Strategy.** This is where we connect to the coherence theorem for ∞-groupoids. The argument proceeds in three stages.

**Stage 1: The structure of elimination obligations.**

When we introduce a HIT X with presentation P at step n+1 and define an eliminator into a type family Y, the obligations decompose by dimension:

- *Dimension 0 obligations:* The point data (d_c) must be well-typed. These reference Y and the types in the current library — at most layer L_n.

- *Dimension 1 obligations:* For each path constructor p : a = b in X, we need a path:

      d_p : transport^Y(p, d_a) = d_b

  The terms appearing here are: transport along p (which involves the path structure of Y over X), d_a and d_b (the point data from dimension 0). The transport function depends on how Y interacts with the path structure of X, which was introduced at step n+1, and the path structure of the types in L_n that Y references.

  Key point: the 1-dimensional obligations reference the *point data* (dimension 0, current step) and the *path structure of the library types* (which live in L_n).

  **These are depth-1 obligations.** They reference the current step and L_n.

- *Dimension 2 obligations:* For each 2-cell s in P, or for each coherence condition between path data, we need a homotopy:

      d_s : (some equation between the d_p's)

  The terms appearing here involve: the paths d_p (dimension 1, current step), path composition and inversion in the library types (which depend on the path *algebra* of types in L_n), and the interaction between paths in L_n and paths that were already present in L_{n-1}.

  **This is the critical point.** The composition of paths in L_n was itself introduced at step n (when that layer's types were defined). The *coherence of that composition* — i.e., the associativity and interchange laws for path composition — depends on the homotopy structure of types from L_{n-1}.

  Specifically: if we have paths p (from L_n) and q (from L_{n-1}), and we need to compose them, the associator

      α : (p · q) · r = p · (q · r)

  is a homotopy that involves structure from both L_n and L_{n-1}. The 2-dimensional obligation for our new eliminator must respect this associator.

  **These are depth-2 obligations.** They reference L_n (for the paths being composed) and L_{n-1} (for the coherence of the composition).

- *Dimension 3 obligations:* Would require coherence conditions on the homotopies from dimension 2. These would involve:
  - The associator for homotopy composition
  - The interchange law between horizontal and vertical composition
  - The pentagon identity for the associator

  **This is where Mac Lane coherence enters.** The coherence theorem (in its ∞-categorical generalization, due to Joyal-Street, and further generalized by Lurie) states:

  > **Coherence Theorem.** In a weak ∞-groupoid, every diagram of canonical coherence cells (associators, unitors, interchangers) whose boundary is well-typed *commutes*.

  In our setting, this means: the dimension 3 obligations are *automatically satisfied* once the dimension 2 obligations are satisfied. The 3-homotopies witnessing coherence of the 2-homotopies are *uniquely determined* — there is no independent choice to be made.

  More precisely: the space of ways to fill a 3-dimensional coherence obligation, given that the 2-dimensional boundary is filled, is *contractible*. This is a consequence of the fact that the type of coherence data for an ∞-groupoid is itself a (−1)-type (a proposition) once we fix the data up to dimension 2.

  **Therefore, dimension 3 obligations generate no independent conditions.** They reference no new library structure. They are determined by the dimension 2 data.

- *Dimension k obligations for k ≥ 3:* By induction, all higher obligations are similarly determined. The coherence theorem propagates: once dimension 2 is fixed, dimension 3 is forced; once dimension 3 is forced, dimension 4 is forced; and so on.

**Stage 2: Why exactly two layers, not one.**

In Stage 1, the critical transition was at dimension 2, where we needed the coherence of path composition. Why does path composition involve two layers?

Because composition is a *binary* operation on paths:

    _·_ : (a =_A b) → (b =_A c) → (a =_A c)

If path p was introduced in L_n (as part of the path structure of a type defined at step n) and path q was introduced in L_{n-1} (as part of the path structure of a type defined at step n-1), then the composite p · q involves both layers. The coherence of this composite — the associator α and the interchange law — is a 2-dimensional condition that genuinely spans both layers.

If we tried to restrict to a depth-1 window (only L_n), we couldn't state the coherence of compositions that involve older paths. But these compositions *do* appear in elimination data: when we define an eliminator for a HIT, the computation rules for path constructors involve transport, and transport composes paths from multiple layers of the library.

**Stage 3: Why not deeper than two.**

The reason that L_{n-2} (and beyond) don't contribute independent obligations is the transitivity of coherence. If we have three paths:
- p from L_n
- q from L_{n-1}
- r from L_{n-2}

The composite p · q · r involves all three layers. But the coherence of this triple composite is determined by the coherences of the pairwise composites:
- α_{p,q,r} : (p · q) · r = p · (q · r)

This associator involves only the *pairwise interactions*: (p, q) and (q, r). The pair (p, q) involves L_n and L_{n-1}. The pair (q, r) involves L_{n-1} and L_{n-2}. But the associator α was already fixed when L_{n-1} was sealed (at that time, q was the "new" structure being introduced, and r was in the preceding layer). So α is *already in the library* by the time we introduce P at step n+1.

**This is the key structural argument:** The coherence data for interactions between L_{n-1} and L_{n-2} was already constructed when L_{n-1} was introduced. We don't need to reconstruct it. We only need *new* coherence data for interactions involving L_n — and those interactions reach back at most one more step, to L_{n-1}.

**Formal claim:** For any triple of consecutive layers (L_k, L_{k+1}, L_{k+2}), the coherence obligations generated when L_{k+2} is introduced that involve L_k are all reducible to:
1. The already-established coherence between L_k and L_{k+1} (from when L_{k+1} was introduced), combined with
2. New coherence between L_{k+1} and L_{k+2} (the depth-2 obligations being generated now).

No *irreducible* obligation references L_k directly. ∎ (for Part 1)

---

#### Part 2: Lower Bound (d ≥ 2)

**Theorem B.2.** There exist cell presentations P such that the coherence obligations for their elimination data genuinely span two layers (i.e., they cannot be reformulated using only the most recent layer).

**Proof by example.**

**Example: The circle S¹ introduced after a type with nontrivial path structure.**

Suppose the library contains:
- Layer L_{n-1}: A type A with a distinguished path p : a =_A b (e.g., A could be an earlier HIT with a loop, or a universe with a nontrivial equivalence)
- Layer L_n: A type B that depends on A, with a function f : A → B and an induced path f(p) : f(a) =_B f(b)

Now we introduce S¹ at step n+1 and define an eliminator:

    rec : S¹ → B

with rec(base) := f(a) and rec(loop) := some_path : f(a) =_B f(a).

The coherence obligation is: the path some_path must be compatible with the path structure of B. In particular, if there are relations between f(p) and the loop structure (e.g., if we're constructing a map that factors through A), we need:

    transport along f(p) composed with some_path = (some equation involving the paths in B derived from paths in A)

The right-hand side involves f(p), which depends on p : a =_A b from L_{n-1} and f from L_n. **This is a genuine depth-2 obligation:** it cannot be stated without referencing both the path p from L_{n-1} and the function f from L_n.

**Sharper example: the Hopf fibration.**

The Hopf fibration h : S³ → S² is defined in HoTT as a map that classifies a principal S¹-bundle over S². Its construction requires:

1. S¹ (from an earlier layer)
2. S² (from a more recent layer)
3. The action of S¹ on itself by multiplication (from the layer where S¹ was introduced)
4. Coherence: the clutching function (S¹ → Aut(S¹)) must be compatible with the path algebra of both S¹ and S²

The coherence conditions for the Hopf fibration's elimination principle involve:
- The loop of S¹ (from the layer where S¹ was introduced — L_{n-1} or earlier)
- The surface of S² (from L_n)
- The interaction between these via the total space S³

This is a depth-2 obligation that cannot be eliminated. ∎

---

### Theorem B (Combined)

**Theorem.** The coherence window of HoTT is exactly d = 2.

**Proof.** By Theorem B.1, d ≤ 2. By Theorem B.2, d ≥ 2. Therefore d = 2. ∎

---

## 5. The Precise Connection to Mac Lane Coherence

The upper bound argument (d ≤ 2) rests on a generalization of the classical Mac Lane coherence theorem. Let me make this precise.

### 5.1 Classical Mac Lane Coherence (1963)

**Theorem (Mac Lane).** In a monoidal category, every diagram of canonical associators and unitors commutes. Equivalently: every monoidal category is monoidally equivalent to a *strict* monoidal category (where associativity and unit laws hold on the nose).

Translated: once you specify the 1-dimensional data (objects and morphisms) and the 2-dimensional coherence data (the associator and pentagon identity), all higher coherence is automatic.

### 5.2 The ∞-Groupoid Generalization

The relevant generalization is:

**Theorem (Coherence for ∞-groupoids, implicit in Lurie, "Higher Topos Theory," Proposition 1.1.2.2 and surrounding material; see also Joyal, "The Theory of Quasi-Categories").** Let G be a weak ∞-groupoid presented by a cell complex with cells in dimensions 0, 1, and 2. Then the ∞-groupoid freely generated by this presentation is *well-defined up to contractible ambiguity*: the space of ways to extend the presentation to all higher dimensions (filling all higher coherence cells) is contractible.

More precisely: given a 2-truncated presentation (generators and relations up to dimension 2), there is an essentially unique ∞-groupoid realizing it. The "essentially unique" means that the space of fillers for all higher cells is a (−1)-type (contractible if inhabited).

**This is exactly what we need.** In our setting:
- The 0-cells are the point constructors of our HIT
- The 1-cells are the path constructors
- The 2-cells are the coherence conditions (the surface constructors, if any, plus the coherence requirements from elimination)

Once these are specified, *all higher coherence is determined*. This is why d = 2: dimensions 0, 1, and 2 are the independent data, and dimension 2 involves exactly two layers of the library (as argued in the proof of Theorem B.1).

### 5.3 Why "Two Layers" and Not "Two Dimensions"

There's a subtlety here that must be addressed. The coherence theorem says the *dimensional* structure stabilizes at dimension 2. But the PEN model's "layers" are not dimensions — they're temporal steps in the library's growth. Why do these correspond?

The correspondence is:

| Dimension | Content | Library reference |
|---|---|---|
| 0 | Point constructors of the new type | Current step n+1 |
| 1 | Path constructors and transport data | Interaction between step n+1 and L_n |
| 2 | Coherence of paths (associativity, interchange) | Interaction between L_n and L_{n-1} |
| ≥ 3 | Higher coherence | Determined by dimensions 0–2 (Mac Lane) |

The key is that dimension k of the new type's coherence data involves *compositions* of k cells from the library. A 1-cell involves one layer. A 2-cell involves the *composition* of 1-cells, which can span two layers. A 3-cell involves the coherence of 2-cells, but this coherence is already in the library (it was established when the intermediate layer was introduced).

So the "temporal depth" (how many layers back) tracks the "compositional depth" (how many cells are being composed), which tracks the "dimensional depth" (what dimension of coherence is needed). And the coherence theorem caps the dimensional depth at 2.

### 5.4 The Saturation Assumption, Revisited

The PEN model assumes "saturation": that the new structure maximally engages with the interface. In the type-theoretic setting, this means:

> When a new HIT is introduced, its elimination principle engages with all available path structure in the library.

This is a natural assumption for HoTT, because the *universal property* of a HIT's eliminator is precisely that it respects *all* the structure. The eliminator for S¹ doesn't just map base somewhere — it must respect the loop, which means it engages with the full path algebra of the target type.

Under saturation:
- Every 1-cell interaction that *can* generate an obligation *does*.
- Every 2-cell coherence condition that *can* be stated *is* required.
- The obligation set O^(d)(P, B_n) is maximal for each d.

This is why the recurrence Δ_{n+1} = Δ_n + Δ_{n-1} holds: the obligations span the full interface of the last two layers, not a subset of it.

---

## 6. What Remains to Be Proved

Let me be completely honest about the status of each component.

### Fully established:

1. **Theorem A (d = 1 for extensional TT):** The argument is straightforward. UIP collapses all coherence to propositions. This could be formalized in Agda (plain Agda, not Cubical) relatively easily.

2. **The lower bound d ≥ 2 for HoTT (Theorem B.2):** The examples are concrete and verifiable. Anyone who has worked with HITs in Cubical Agda knows that elimination principles require genuine path coherence data. The Hopf fibration example is particularly convincing.

3. **The Mac Lane coherence theorem itself:** This is a classical result with multiple formal proofs.

### Established but requires careful formalization:

4. **The ∞-groupoid coherence theorem (Section 5.2):** This is "well-known to experts" but the precise statement we need — that cell presentations with data up to dimension 2 have contractible spaces of higher fillers — requires extracting the right result from the ∞-categorical literature. The most precise reference is Lurie's proof that every ∞-groupoid is equivalent to a Kan complex, combined with the fact that Kan complexes are determined by their 2-skeleton up to contractible ambiguity (under suitable conditions on the presentation).

    **This is the step that needs the most work.** The statement is true, but extracting it from the homotopical algebra literature and translating it into type-theoretic language is nontrivial.

5. **The correspondence between "dimensional depth" and "temporal depth" (Section 5.3):** This is the bridge between the coherence theorem (which is about dimensions) and the PEN model (which is about layers). The argument in Section 5.3 is informal. Making it precise requires:
   - A formal definition of "the layer referenced by a k-dimensional obligation"
   - A proof that k-dimensional obligations reference at most ⌈k/1⌉ = k layers (trivially)
   - The key claim: that k ≥ 3 dimensional obligations are *reducible* to k ≤ 2 obligations (via coherence), and these k ≤ 2 obligations reference at most 2 layers

### Open / conjectural:

6. **The upper bound d ≤ 2 in full generality (Theorem B.1):** The proof strategy in Section 4 is sound, but the argument in Stage 3 ("why not deeper than two") relies on the claim that the coherence data between L_{n-1} and L_{n-2} was *already established* when L_{n-1} was introduced. This is true *under the assumption that each layer is fully sealed before the next is introduced* — which is exactly the PEN model's sequential construction assumption. But making this completely precise requires:
   - Formalizing what it means for a layer to be "fully sealed"
   - Showing that full sealing at step k implies that all coherence between L_k and L_{k-1} is available at step k+1
   - This is a property of the cumulative nature of the type-theoretic library, and should follow from the closure properties of the ambient type theory

7. **The precise operator count (|S(L_k)| = Δ_k):** The PEN model assumes that each layer exports exactly as many schemas as its integration cost. In the type-theoretic setting, this means: the number of *independent coherence interfaces* exported by a layer equals the number of coherence obligations it incurred when it was introduced. This is plausible (what you had to respect when you came in is what you offer to the next arrival) but needs a formal argument.

---

## 7. Formalization Strategy

### 7.1 The Cubical Agda Path

The most convincing formalization would proceed in Cubical Agda:

**Step 1: Formalize the elimination principle for a generic 2-truncated HIT.**
- Define a data type representing cell presentations up to dimension 2
- Show that the elimination data for such a presentation consists of exactly the data described in Definition 3.4

**Step 2: Show that the coherence conditions on elimination data are determined by the 2-dimensional cells.**
- For a specific family of HITs (circles, spheres, tori), verify computationally that the Agda type-checker requires exactly 2-dimensional coherence data and no more
- This is already *implicitly* verified every time someone defines a HIT in Cubical Agda — the type-checker doesn't ask for 3-dimensional data because it's contractible

**Step 3: Formalize the "layer reference" analysis.**
- For a concrete example (e.g., defining the Hopf fibration given S¹ and S²), trace which library elements appear in each coherence obligation
- Show that 2-dimensional obligations reference two layers and 3-dimensional obligations (if any) are contractible

**Step 4: Abstract to the general case.**
- This is the hardest step and might not be achievable purely in Agda
- An alternative: prove the general theorem on paper (using the ∞-groupoid coherence theorem) and formalize only the d=2 recurrence consequence in Agda (which you've already started)

### 7.2 The Paper Path

If full formalization is too ambitious in the near term, a rigorous paper proof would proceed:

1. State the ∞-groupoid coherence theorem precisely (citing Lurie/Joyal)
2. Define "coherence obligation" and "layer reference" formally
3. Prove the correspondence between dimensional depth and temporal depth
4. Derive d = 2 as a corollary

This would be publishable in a foundations/logic journal on its own merits, independent of PEN.

### 7.3 The Computational Evidence Path

As a complement to either formal path, run the following experiments in Cubical Agda:

For each of the following HITs: S¹, S², T², S³, the Hopf fibration, and the James construction:

1. Define the HIT
2. Define a non-trivial eliminator into a type family over a preceding HIT
3. Record every goal that Agda presents during the construction
4. Classify each goal by the layer(s) it references
5. Verify: all goals reference at most 2 layers; at least one goal genuinely references 2 layers; no goal references 3 layers

If this holds for 6+ diverse examples, the empirical case is very strong even before the general theorem is proved.

---

## 8. Potential Failure Modes

### 8.1 What if d > 2?

If we discover a construction whose coherence obligations genuinely span 3+ layers, the possibilities are:

**8.1a: The construction involves non-standard cells.** Some exotic HITs (e.g., those with infinitely many constructors, or constructors of unbounded dimension) might escape the coherence theorem. If so, the resolution is to restrict the candidate grammar to *finitely presented* HITs — which is what the PEN model already does.

**8.1b: The coherence theorem doesn't apply as stated.** If the ∞-groupoid coherence theorem requires stronger conditions than HoTT provides, d could be larger. In this case, the PEN model still works — we just need to determine the actual d and check whether the Genesis Sequence holds for that d. (The general scaling theorem works for any d.)

**8.1c: The "temporal depth = compositional depth" correspondence fails.** If layers can interact in ways that don't track compositional depth (e.g., through universe polymorphism or very large eliminations), the mapping between d-as-dimension and d-as-layer-depth could break. This is perhaps the subtlest potential failure mode.

### 8.2 What if d < 2?

If all coherence obligations in HoTT can be reduced to depth 1, the theory would predict constant Δ (like the extensional case). This would contradict the observed richness of HoTT and is extremely unlikely, but the lower bound (Theorem B.2) is precisely the proof that this doesn't happen.

---

## 9. Connection to the Literature

The following existing results are directly relevant:

1. **Mac Lane (1963), "Natural Associativity and Commutativity"**: The original coherence theorem for monoidal categories. Establishes that all diagrams of canonical isomorphisms commute.

2. **Stasheff (1963), "Homotopy Associativity of H-Spaces"**: Introduces the associahedra K_n and shows that A_∞-structures are determined by a finite amount of coherence data. The relevant fact: K_3 (the pentagon) is the last *non-trivial* polytope in the sense that higher associahedra are determined by it.

3. **Joyal-Street (1993), "Braided Tensor Categories"**: Extends Mac Lane coherence to braided monoidal categories. Relevant because path composition in HoTT is not just associative but has higher structure.

4. **Lurie (2009), "Higher Topos Theory"**: Chapters 1–2 establish the theory of ∞-categories and ∞-groupoids. Proposition 1.2.5.1 and surrounding material on Kan complexes and their homotopy theory provides the technical foundation for the ∞-groupoid coherence theorem.

5. **Lumsdaine (2010), "Weak ω-Categories from Intensional Type Theory"**: Shows that the identity types of MLTT form a weak ω-category. This is the precise statement that HoTT's path structure is an ∞-groupoid, which is the starting point for applying the coherence theorem.

6. **van den Berg-Garner (2011), "Types are Weak ω-Groupoids"**: Another proof that identity types form ∞-groupoids, with a more explicit analysis of the coherence structure.

7. **Kraus-von Raumer (2019), "Coherence via Well-Foundedness"**: Develops techniques for proving coherence results in HoTT itself. May provide tools for the formalization.

8. **Shulman (2019), "All (∞,1)-Toposes Have Strict Univalent Universes"**: Establishes key properties of the ∞-categorical semantics of HoTT. Relevant background for understanding what the coherence window means semantically.

---

## 10. Recommended Next Steps (in priority order)

1. **Run the computational evidence experiments (Section 7.3).** This is fast, concrete, and will either build confidence or reveal surprises. Estimated effort: 2–3 weeks for someone fluent in Cubical Agda.

2. **Write out the proof of Theorem A (d = 1) in full detail.** This is the easy case and will serve as a template for the harder proof. Estimated effort: 1 week.

3. **Pin down the precise ∞-groupoid coherence statement needed.** Read Lurie's HTT Chapter 1 and Lumsdaine (2010) carefully. Extract the specific theorem that "2-truncated presentations have contractible spaces of higher fillers." This might already be stated somewhere; if not, it should be derivable. Estimated effort: 2–4 weeks (mostly reading and translation).

4. **Formalize the dimensional-to-temporal correspondence (Section 5.3).** This is the novel mathematical content — the bridge between existing coherence theorems and the PEN model. Estimated effort: 4–6 weeks for a careful paper proof.

5. **Attempt Cubical Agda formalization of the key components.** Start with the lower bound (Theorem B.2) — concrete examples are the most Agda-friendly. Estimated effort: 2–3 months for a working formalization of the main examples.

---

## Appendix: Worked Example — Sealing S² into a Library Containing S¹

To make the abstract framework concrete, we trace the coherence obligations for a specific case.

**Setup:**
- L_{n-1} contains: the universe U, basic type formers, the unit type
- L_n contains: S¹ = HIT{base : S¹, loop : base =_{S¹} base}
- We now introduce: S² = HIT{base₂ : S², surf : refl_{base₂} =_{base₂ =_{S²} base₂} refl_{base₂}}

**Elimination data for a map f : S² → Y:**
- Point: f(base₂) : Y — needs base₂ from current step. **Depth 0.**
- Surface: f(surf) : ap_f(refl) = refl in (f(base₂) =_Y f(base₂)) — this is a path-between-paths in Y.

**The coherence question:** f(surf) must live in the type:

    refl_{f(base₂)} =_{f(base₂) =_Y f(base₂)} refl_{f(base₂)}

This type is π₂(Y, f(base₂)) — the second homotopy group of Y at f(base₂). Its structure depends on:
- The path space of Y (from L_n, since Y may be built using S¹)
- The composition structure of paths in Y (which involves L_n)
- The coherence of this composition (which, if Y involves S¹, references the loop in S¹ from L_n and the basic type-theoretic infrastructure from L_{n-1})

**Tracing the layer references:**
1. f(base₂) references Y. If Y = S¹, this references L_n. **Depth 1.**
2. f(surf) is a 2-path in Y. Its type involves the path composition in Y. If Y = S¹, path composition in S¹ involves the loop (from L_n) and the groupoid laws (from the ambient type theory, which were established using L_{n-1}'s infrastructure). **Depth 2.**
3. Any 3-dimensional coherence (e.g., that f(surf) respects some higher structure) would involve the associator for path composition in S¹. But by Mac Lane coherence (applied to the ∞-groupoid structure of S¹), this associator is the unique canonical one. **No independent condition. Depth 2 suffices.**

This example confirms: d = 2 obligations arise naturally, and d ≥ 3 obligations are automatically satisfied.
