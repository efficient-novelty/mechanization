\documentclass[11pt,a4paper]{article}

% ============================================
% PACKAGES
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{float}
\usepackage{microtype}
\usepackage{xcolor}

\geometry{margin=1in}

\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    citecolor=green!50!black,
    urlcolor=blue!70!black
}

% ============================================
% THEOREM ENVIRONMENTS
% ============================================
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{axiom}[theorem]{Axiom}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% ============================================
% CUSTOM COMMANDS
% ============================================
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\U}{\mathcal{U}}

% ============================================
% TITLE
% ============================================
\title{\textbf{The Principle of Efficient Novelty:\\
Coherence Windows and the Nature of Mathematical Construction}}

\author{Halvor Lande\\
\texttt{hsl@awc.no}}

\date{February 2026}

% ============================================
% DOCUMENT
% ============================================
\begin{document}

\maketitle

% ============================================
% ABSTRACT
% ============================================
\begin{abstract}
Mathematical foundations differ not only in their logical primitives, but in their \emph{Coherence Window}---the depth of historical context required to stabilize structural obligations.
We introduce the \emph{Principle of Efficient Novelty} (PEN), a formal model of mathematical evolution in which a computational agent selects structures maximizing combinatorial enabling power relative to integration cost.
We establish three results.
First, the \textbf{Complexity Scaling Theorem}: foundations with a Coherence Window of exactly~2 (e.g., intensional type theory) force integration costs to follow the Fibonacci sequence, $\Delta_n = F_n$, with realization times $\tau_n = F_{n+2} - 1$.
Second, the \textbf{Stagnation Theorem}: foundations with a Coherence Window of~1 (e.g., extensional set theory) have bounded integration costs and exhibit asymptotic efficiency collapse.
Third, the \textbf{Combinatorial Novelty Theorem}: in constructive type theory, novelty grows superlinearly with integration cost---exponentially ($2^{\Delta_0}$) for ordinary inductive types, and at least linearly via library cross-interactions for higher inductive types---ensuring that efficiency permanently outpaces the rising selection bar.

Applied to an empty library, these axioms produce the \emph{Genesis Sequence}: 15~mathematical structures---from dependent types through spheres, cohesion, and differential geometry to the Dynamical Cohesive Topos---in a deterministic order governed by the Golden Ratio~$\varphi$.
The companion paper~\cite{pen-genesis} exhibits the complete sequence and verifies it computationally.
\end{abstract}

\tableofcontents
\newpage

% ============================================
% SECTION 1: INTRODUCTION
% ============================================
\section{Introduction}
\label{sec:intro}

Why do some mathematical foundations naturally support the emergence of high-dimensional geometric structures, while others remain confined to discrete combinatorics?
The historical shift from extensional foundations (ZFC, Martin-L\"of Type Theory with UIP) to intensional foundations (Homotopy Type Theory~\cite{hott}, Cubical Type Theory~\cite{cubical}) is often viewed as a semantic refinement regarding the treatment of equality.
Viewed through the lens of computational complexity, this shift represents a \emph{phase transition} in the evolutionary dynamics of the system.

In an extensional system, equality is a proposition; checking it is a static operation.
In an intensional system, equality is data (a path); checking it requires constructing a witness that must cohere with the surrounding topological context.
This imposes an \emph{integration cost} on new structures: a candidate definition must be ``sealed'' against previous layers of the theory.

This paper proposes that the dynamics of mathematical evolution are determined by the \emph{Coherence Window} of the foundation---the depth of history required to resolve these obligations.
By abstracting away surface syntax and modeling evolution via \emph{Obligation Graphs}, we resolve a puzzle observed in computational experiments: distinct foundations (e.g., Cubical vs.\ Simplicial Type Theory) generate identical cost trajectories.
This is a consequence of \emph{Graph Isomorphism} in their coherence obligations---if two foundations share the same Coherence Window, they impose isomorphic integration costs on the abstract structures they realize.

\medskip
\noindent\textbf{Contributions.}
\begin{enumerate}[label=(\roman*), leftmargin=*]
    \item We classify foundations by their Coherence Window $d$ and prove that for $d = 2$, integration costs satisfy $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$ (the Fibonacci recurrence), with realization times $\tau_n = F_{n+2} - 1$ (\cref{sec:scaling}).

    \item We prove that $d = 1$ foundations stagnate: constant costs lead to bounded efficiency and asymptotic collapse (\cref{sec:scaling}, \S\ref{sec:stagnation}).

    \item We prove that in constructive type theory, novelty grows superlinearly with integration cost: exponentially for ordinary inductive types, and at least linearly (with multiplicative synthesis amplification) for higher inductive types, ensuring unbounded efficiency growth (\cref{sec:exponentiality}).

    \item We present the Genesis Sequence---15 structures produced by these axioms applied to an empty library---and verify it computationally (\cref{sec:genesis,sec:verification}).
\end{enumerate}

% ============================================
% SECTION 2: THE GENESIS SEQUENCE
% ============================================
\section{The Genesis Sequence}
\label{sec:genesis}

Before developing the formal framework, we present its principal output: the \emph{Genesis Sequence}.
This is the complete evolutionary trace produced by the Principle of Efficient Novelty applied to an intensional type-theoretic foundation.
The model operates on abstract Obligation Graphs rather than syntactic artifacts; it generates candidate structures, computes their integration costs, and selects the candidate maximizing efficiency.
The reader should treat \cref{tab:genesis} as an empirical fact to be explained; the remainder of the paper defines the model that produces it.

\begin{table}[H]
\centering
\caption{The Genesis Sequence}
\label{tab:genesis}
\small
\begin{tabular}{@{}cr l rrrr rrr@{}}
\toprule
$n$ & $\tau$ & Structure & $\Delta_n$ & $\nu$ & $\kappa$ & $\rho$ & $\Phi_n$ & $\Omega_{n-1}$ & Bar \\
\midrule
1  & 1    & Universe $\U_0$              & 1   & 1   & 2 & 0.50  & ---  & ---  & ---  \\
2  & 2    & Unit type $\mathbf{1}$       & 1   & 1   & 1 & 1.00  & 1.00 & 0.50 & 0.50 \\
3  & 4    & Witness $\star : \mathbf{1}$ & 2   & 2   & 1 & 2.00  & 2.00 & 0.67 & 1.33 \\
4  & 7    & $\Pi$/$\Sigma$ types         & 3   & 5   & 3 & 1.67  & 1.50 & 1.00 & 1.50 \\
5  & 12   & Circle $S^1$                 & 5   & 7   & 3 & 2.33  & 1.67 & 1.29 & 2.14 \\
6  & 20   & Propositional truncation     & 8   & 8   & 3 & 2.67  & 1.60 & 1.60 & 2.56 \\
7  & 33   & Sphere $S^2$                 & 13  & 10  & 3 & 3.33  & 1.62 & 1.85 & 3.00 \\
8  & 54   & $S^3 \cong \mathrm{SU}(2)$  & 21  & 18  & 5 & 3.60  & 1.62 & 2.12 & 3.43 \\
9  & 88   & Hopf fibration               & 34  & 17  & 4 & 4.25  & 1.62 & 2.48 & 4.01 \\
10 & 143  & Cohesion                     & 55  & 19  & 4 & 4.75  & 1.62 & 2.76 & 4.46 \\
11 & 232  & Connections                  & 89  & 26  & 5 & 5.20  & 1.62 & 3.03 & 4.91 \\
12 & 376  & Curvature tensors            & 144 & 34  & 6 & 5.67  & 1.62 & 3.35 & 5.42 \\
13 & 609  & Metric + frame bundle        & 233 & 43  & 7 & 6.14  & 1.62 & 3.70 & 5.99 \\
14 & 986  & Hilbert functional           & 377 & 60  & 9 & 6.67  & 1.62 & 4.06 & 6.58 \\
15 & 1596 & Dynamical Cohesive Topos     & 610 & 150 & 8 & 18.75 & 1.62 & 4.48 & 7.25 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Guided Reading}

The table records 15 \emph{realizations}---mathematical structures selected in sequence from an empty library.
Each row is characterized by:
\begin{itemize}[nosep]
    \item $n$: realization index.
    \item $\tau$: cumulative realization time ($= F_{n+2} - 1$).
    \item $\Delta_n$: \emph{Integration Latency}---the cost of sealing the structure against the library ($= F_n$).
    \item $\nu$: \emph{Novelty}---the count of newly enabled constructions.
    \item $\kappa$: \emph{Construction Effort}---the definitional complexity.
    \item $\rho = \nu/\kappa$: \emph{Efficiency}---the selection score.
    \item $\Phi_n = \Delta_n / \Delta_{n-1}$: \emph{Structural Inflation}, converging to $\varphi$.
    \item $\Omega_{n-1}$: \emph{Cumulative Baseline}---the library's historical efficiency ($\sum \nu_i / \sum \kappa_i$).
    \item $\mathrm{Bar} = \Phi_n \cdot \Omega_{n-1}$: the selection threshold.
\end{itemize}

Three patterns are verifiable by inspection:

\paragraph{1. Fibonacci Timing.}
The $\Delta_n$ column is the Fibonacci sequence: $1, 1, 2, 3, 5, 8, 13, 21, \ldots, 610$.
The $\tau$ column is its cumulative sum: $\tau_n = F_{n+2} - 1$.
This is not a numerical coincidence; we prove in \cref{sec:scaling} that it is the unique cost schedule for foundations with a two-step coherence window.

\paragraph{2. Selective Survival.}
Every realized structure clears the selection bar: $\rho_n \ge \mathrm{Bar}_n$.
The tightest margin is at $n = 4$: dependent types ($\rho = 1.67$) clear the bar ($1.50$) by only $0.17$.
This narrow passage is structurally necessary---the system must invest in foundational infrastructure before the geometric payoff begins.
Not all candidates survive: Lie groups ($\kappa = 6$, $\nu = 9$, $\rho = 1.50$) are \emph{absorbed} rather than realized, as their efficiency falls far below the bar ($\approx 4.46$) at the time they become reachable.

\paragraph{3. Four Phases.}
\begin{itemize}[nosep]
    \item \textbf{Bootstrap} ($n = 1$--$4$): A universe, a type, an inhabitant, dependent types.
    \item \textbf{Geometric Ascent} ($n = 5$--$9$): The circle, spheres, the Hopf fibration.
    \item \textbf{Framework Abstraction} ($n = 10$--$14$): Cohesion~\cite{lawvere,schreiber}, connections, curvature, metrics, Hilbert.
    \item \textbf{Synthesis} ($n = 15$): The Dynamical Cohesive Topos clears the bar by a factor of $2.6$.
\end{itemize}

\subsection{The Claims}

The remainder of this paper establishes three results that, taken together, explain why the Genesis Sequence has the structure it does.

\begin{enumerate}[label=\textbf{Claim \arabic*.}, leftmargin=*]
    \item \textbf{Fibonacci costs are necessary} (\cref{sec:scaling}, \cref{thm:scaling}).
    For any foundation whose coherence obligations span exactly two layers, $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$.
    With minimal initial conditions, $\Delta_n = F_n$.

    \item \textbf{Extensional foundations stagnate} (\cref{sec:scaling}, \S\ref{sec:stagnation}).
    Foundations whose obligations span one layer have constant costs.
    The resulting evolution is linear and efficiency growth decays to zero.

    \item \textbf{Novelty scales superlinearly with cost} (\cref{sec:exponentiality}, \cref{thm:exponentiality}).
    In constructive type theory, an ordinary inductive type with $\Delta_0$ point-constructors enables $2^{\Delta_0}$ distinguishable predicates at linear definitional cost.
    For higher inductive types, path-constructor coherence reduces Boolean predicates, but library cross-interactions and synthesis multiplicativity restore superlinear novelty growth.
    This ensures that efficiency permanently outpaces the selection bar.
\end{enumerate}

These three claims explain, respectively, the $\Delta_n$ column (Fibonacci), the contrast with extensional alternatives (stagnation), and the sustained growth of $\rho_n$ (exponential novelty).

% ============================================
% SECTION 3: FORMAL FRAMEWORK
% ============================================
\section{Formal Framework}
\label{sec:framework}

We model mathematical evolution as a discrete-time optimization process operating on a state $\mathcal{B}$ (the ``Library'').
At each step, the system generates candidate extensions, calculates their \emph{Efficiency} $\rho = \nu / \kappa$, and selects the optimal candidate.
The framework separates the \emph{Latency} required to witness historical coherence from the \emph{Effort} required to specify new structure.

\subsection{State and Candidates}

\begin{definition}[State]
\label{def:state}
A \emph{State} $\mathcal{B}$ is a monotone context (a category of contexts) closed under derivability.
An evolution step $\mathcal{B}_n \leadsto \mathcal{B}_{n+1}$ is an extension by a single sealed structure.
\end{definition}

\begin{definition}[Candidate]
\label{def:candidate}
A \emph{Candidate} $X$ is a pair $(X_{\mathrm{core}}, \mathcal{G}_{\mathrm{obl}})$, where $X_{\mathrm{core}}$ is the definitive data (type formers, constructors) and $\mathcal{G}_{\mathrm{obl}}$ is the \emph{Obligation Graph}: the set of atomic coherence obligations required to seal $X$ against the history.
\end{definition}

\subsection{The Dual-Cost Model}

We distinguish between the cost of \emph{waiting} (Time) and the cost of \emph{building} (Complexity).

\begin{definition}[Integration Latency]
\label{def:latency}
The \emph{Integration Latency} $\Delta(X \mid \mathcal{B})$ is the cardinality of the Obligation Graph:
\begin{equation}
    \Delta(X \mid \mathcal{B}) := |\mathcal{G}_{\mathrm{obl}}|
\end{equation}
Latency is paid in \emph{time}: high latency means the system must accumulate significant historical context before the structure becomes realizable.
\end{definition}

\begin{definition}[Construction Effort]
\label{def:effort}
The \emph{Construction Effort} $\kappa(X)$ is the count of atomic generators (constructors, axioms) required to specify $X$ given the interface:
\begin{equation}
    \kappa(X) := |X_{\mathrm{core}}|
\end{equation}
Effort is the denominator of efficiency.
\end{definition}

\subsection{The Disjoint Interface}

The magnitude of the Integration Latency is determined by the foundation's Coherence Window.

\begin{definition}[Interface Basis]
\label{def:interface}
For a foundation with Coherence Window $d$, the \emph{Interface Basis} available for sealing candidate $X_{n+1}$ is the disjoint union of the schemas exported by the previous $d$ layers:
\begin{equation}
    I^{(d)}_n := \biguplus_{j=0}^{d-1} S(L_{n-j})
\end{equation}
\end{definition}

\begin{lemma}[Latency Recurrence]
\label{lem:recurrence}
Assuming the system saturates the interface to maximize connectivity:
\begin{equation}
    \Delta_{n+1} = |I^{(d)}_n| = \sum_{j=0}^{d-1} \Delta_{n-j}
\end{equation}
For $d = 2$: $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$, i.e., $\Delta_n = F_n$.
\end{lemma}

\subsection{Novelty and Efficiency}

Effort captures cost; we need a dual notion of benefit.
A structure is valuable not in itself but for what it enables.
Dependent types are powerful not because they are large but because they unlock an entire universe of constructions.
We formalize this through the \emph{frontier}---the set of structures accessible within a given effort bound.

\begin{definition}[Canonical Frontier]
\label{def:frontier}
Given state $\mathcal{B}$ and effort horizon $H \in \N$, the \emph{frontier} is:
\begin{equation}
    \mathcal{S}(\mathcal{B}, H) := \{Y \text{ (sealed schema)} \mid K_{\mathcal{B}}(Y) \leq H\}
\end{equation}
\end{definition}

\begin{definition}[Novelty]
\label{def:novelty}
The \emph{novelty} of sealed candidate $X$ relative to base $\mathcal{B}$ and horizon $H$:
\begin{equation}
    \nu(X \mid \mathcal{B}, H) := \left|\left\{Y \in \mathcal{S}(\mathcal{B}, H) \cup \mathcal{S}(\mathcal{B} \cup \{X\}, H) \,\middle|\, K_{\mathcal{B}}(Y) - K_{\mathcal{B} \cup \{X\}}(Y) \geq 1\right\}\right|
\end{equation}
Structures with $K_{\mathcal{B}}(Y) = \infty$ but $K_{\mathcal{B} \cup \{X\}}(Y) < \infty$ contribute---these are constructions that were impossible before $X$ but become reachable after.
\end{definition}

\begin{definition}[Efficiency]
\label{def:efficiency}
\begin{equation}
    \rho(X) := \frac{\nu(X)}{\kappa(X)}
\end{equation}
\end{definition}

\begin{definition}[Realization Time]
\label{def:tau}
The cumulative Integration Latency:
\begin{equation}
    \tau_n := \sum_{i=1}^{n} \Delta_i = F_{n+2} - 1 \quad \text{(for $d = 2$)}
\end{equation}
\end{definition}

\subsection{Selection Dynamics}

\begin{definition}[Structural Inflation]
\label{def:inflation}
\begin{equation}
    \Phi_n := \frac{\Delta_n}{\Delta_{n-1}} = \frac{F_n}{F_{n-1}} \xrightarrow{n \to \infty} \varphi \approx 1.618
\end{equation}
\end{definition}

\begin{remark}[Why $\Phi_n \neq \tau_n / \tau_{n-1}$]
\label{rem:phi-not-tau}
At $n = 4$, $\tau_4/\tau_3 = 7/4 = 1.75$, which would raise the bar above $\rho_4 = 1.67$, killing the infrastructure phase.
The correct definition $\Phi_4 = \Delta_4/\Delta_3 = 3/2 = 1.50$ allows dependent types to survive.
Inflation should measure the \emph{marginal} growth of interface debt, not the cumulative burden.
\end{remark}

\begin{definition}[Cumulative Baseline]
\label{def:omega}
\begin{equation}
    \Omega_{n-1} := \frac{\sum_{i=1}^{n-1} \nu_i}{\sum_{i=1}^{n-1} \kappa_i}
\end{equation}
The cumulative ratio is dominated by the bulk of the library, preventing outliers from distorting the threshold.
\end{definition}

\subsection{The Five Axioms}

\begin{axiom}[Cumulative Growth]
\label{ax:cumulative}
$R(\tau - 1) \subseteq R(\tau)$ for all $\tau$.
Mathematics only grows; realized structures are never removed.
\end{axiom}

\begin{axiom}[Horizon Policy]
\label{ax:horizon}
A global effort horizon $H \in \N$ governs the search space.
After each realization: $H \leftarrow 2$.
After each idle tick: $H \leftarrow H + 1$.
\end{axiom}

The horizon resets after each success, forcing the system to search locally before exploring more distant constructions.

\begin{axiom}[Admissibility]
\label{ax:admissibility}
A sealed candidate $X$ over base $\mathcal{B} = R(\tau - 1)$ is \emph{admissible} iff:
\begin{enumerate}[nosep]
    \item $X$ is derivable from $\mathcal{B}$ (i.e., $K_{\mathcal{B}}(X) < \infty$), and
    \item $\kappa(X) \leq H$.
\end{enumerate}
\end{axiom}

\begin{axiom}[Selection]
\label{ax:selection}
The \emph{Selection Bar} is $\mathrm{Bar}_n := \Phi_n \cdot \Omega_{n-1}$.
From admissible candidates, select $X$ with $\rho(X) \geq \mathrm{Bar}_n$ and minimal positive overshoot:
\begin{equation}
    X \in \arg\min_{Y\,:\, \rho(Y) \geq \mathrm{Bar}_n} \bigl(\rho(Y) - \mathrm{Bar}_n\bigr)
\end{equation}
Ties are broken by minimal $\kappa$; remaining ties realize in superposition.
If no candidate clears the bar, the tick idles.
\end{axiom}

The minimal-overshoot criterion selects the most ``natural'' next step rather than an efficiency outlier.

\begin{axiom}[Coherent Integration]
\label{ax:integration}
When candidate $X_{n+1}$ is realized, it is integrated coherently by establishing coherence witnesses with recently realized structures.
This produces an integration layer $L_{n+1}$ with \emph{integration gap} $\Delta_{n+1} := \kappa(L_{n+1})$.
\end{axiom}

\begin{remark}
\label{rem:integration}
\cref{ax:integration} leaves open how many prior layers constitute ``relevant context.''
\cref{sec:scaling} establishes that exactly two layers---$L_n$ and $L_{n-1}$---constitute the optimal strategy for intensional foundations.
\end{remark}

% ============================================
% SECTION 4: COHERENCE DIMENSIONS
% ============================================
\section{Coherence Dimensions}
\label{sec:coherence}

We now apply the framework to classify concrete mathematical foundations.
``Dimension'' here is not geometric intuition but the operational depth required to stabilize the Obligation Graph.

\subsection{Induced Obligations}

\begin{definition}[Induced Obligations]
\label{def:obligations}
Let $\mathcal{O}^{(k)}(X)$ denote the set of normalized atomic obligations induced when candidate $X$ is sealed against a history of depth $k$.
Because the interface is a cumulative disjoint union (\cref{def:interface}):
\begin{equation}
    \mathcal{O}^{(1)}(X) \subseteq \mathcal{O}^{(2)}(X) \subseteq \mathcal{O}^{(3)}(X) \subseteq \cdots
\end{equation}
\end{definition}

\begin{definition}[Coherence Window]
\label{def:window}
A foundation has Coherence Window $d$ if the induced obligations stabilize at depth $d$:
for all valid candidates $X$ and all $k \geq d$,
\begin{equation}
    \mathcal{O}^{(k)}(X) \cong \mathcal{O}^{(d)}(X)
\end{equation}
\end{definition}

\subsection{Obligation Reducibility}

Before classifying foundations, we make precise what it means for an obligation to be irreducible at a given layer depth.

\begin{definition}[Obligation Reduction]
\label{def:reduction}
Let $o \in \mathcal{O}^{(k)}(X)$ be an atomic obligation referencing layers $L_{n}, L_{n-1}, \ldots, L_{n-j}$.
We say $o$ \emph{reduces at depth~$j$} if there exist obligations $o_1, \ldots, o_m \in \mathcal{O}^{(j-1)}(X)$, each referencing only layers $L_n, \ldots, L_{n-j+1}$, such that:
\begin{equation}
    o \text{ is satisfied} \iff o_1, \ldots, o_m \text{ are all satisfied}
\end{equation}
An obligation is \emph{irreducible at depth~$j$} if it references layer $L_{n-j+1}$ and does not reduce at depth~$j$.
\end{definition}

\begin{definition}[Coherence Obligation by Dimension]
\label{def:dim-obligation}
When a candidate $X$ with cell presentation $P = (C_0, C_1, C_2, \ldots)$ is sealed against library state $B_n$, the elimination data for a type family $Y : X \to \mathcal{U}$ decomposes by dimension:
\begin{itemize}[nosep]
    \item \emph{Dimension~0:} For each $c \in C_0$, a point $d_c : Y(c)$.
    \item \emph{Dimension~1:} For each $p \in C_1$ with $p : a = b$, a path $d_p : \mathrm{transport}^Y(p, d_a) = d_b$.
    \item \emph{Dimension~$k$:} For each $k$-cell $s \in C_k$, a $k$-path $d_s$ witnessing coherence of the $(k{-}1)$-dimensional data.
\end{itemize}
\end{definition}

\subsection{Theorem A: Extensional Systems ($d = 1$)}
\label{sec:thmA}

\textbf{Examples:} ZFC, Martin-L\"of Type Theory with UIP.

\begin{theorem}[Extensional Coherence Window]
\label{thm:ext-window}
In MLTT + UIP (or any type theory where identity types are h-propositions), the Coherence Window is $d = 1$.
\end{theorem}

\begin{proof}
We show both bounds: $d \leq 1$ (upper) and $d \geq 1$ (lower).

\medskip\noindent\textbf{Upper bound ($d \leq 1$).}
Let $X$ be a candidate sealed at step $n+1$ with elimination into a type family $Y : X \to \mathcal{U}$.

\emph{Step~1 (h-set collapse).}
In MLTT+UIP, all types are h-sets: for any $a, b : A$, the identity type $a =_A b$ is either empty or contractible.  This is the content of the Uniqueness of Identity Proofs axiom.

\emph{Step~2 (Forced path data).}
The dimension-0 obligations require choosing points $d_c : Y(c)$ for each constructor $c$.  These reference only the types in $Y$ and the current library $L_n$.

For dimension-1 obligations, each path constructor $p : a = b$ in $X$ requires a path
\[
    d_p : \mathrm{transport}^Y(p, d_a) = d_b.
\]
Since $Y(b)$ is an h-set, the type $\mathrm{transport}^Y(p, d_a) =_{Y(b)} d_b$ is a proposition.  Therefore $d_p$ is either impossible (no inhabitant) or unique (exactly one inhabitant).  In neither case does the \emph{choice} of $d_p$ constitute independent data.

\emph{Step~3 (No higher coherence).}
Dimension-2 obligations would require coherence between paths, i.e., a homotopy $h : d_p \cdot d_q = d_r$ for some configuration.  But in an h-set, any two parallel paths are equal (propositionally), so any such equation holds automatically.  Formally: the type of 2-cells between any two 1-cells in an h-set is contractible.

By induction, all dimension-$k$ obligations for $k \geq 2$ are trivially satisfied.

\emph{Step~4 (Stabilization).}
Since dimension-0 and dimension-1 obligations reference only $L_n$ (the current layer), and all higher-dimensional obligations are trivial, we have $\mathcal{O}^{(k)}(X) \cong \mathcal{O}^{(1)}(X)$ for all $k \geq 1$.

\medskip\noindent\textbf{Lower bound ($d \geq 1$).}
The bound is tight: $d = 0$ would mean no obligations at all, but introducing any structure $X$ requires at minimum checking well-typedness of its constructors against $L_n$.  Since $L_n$ contributes irreducible obligations (the point data must inhabit types defined at step $n$), we have $d \geq 1$.
\end{proof}

\begin{remark}
\Cref{thm:ext-window} applies equally to ZFC (where ``types'' are sets and there are no independent identity proofs) and to any set-level foundation.  The essential property is that the identity type functor is valued in propositions.
\end{remark}

\subsection{Theorem B: Intensional Systems ($d = 2$)}
\label{sec:thmB}

\textbf{Examples:} Homotopy Type Theory~\cite{hott}, Cubical Type Theory~\cite{cubical}, Simplicial Type Theory.

\begin{theorem}[Intensional Coherence Window]
\label{thm:int-window}
In HoTT (or Cubical Type Theory), the Coherence Window is $d = 2$.
\end{theorem}

The proof splits into an upper bound (Theorem~B.1) and a lower bound (Theorem~B.2).

\subsubsection{Upper Bound: $d \leq 2$}

\begin{theorem}[Coherence Upper Bound]
\label{thm:upper}
For any cell presentation $P$ introduced at step $n+1$, every irreducible coherence obligation for the elimination data of $P$ references at most layers $L_n$ and $L_{n-1}$.
\end{theorem}

\begin{proof}
The argument has three stages.

\medskip\noindent\textbf{Stage~1: Obligation decomposition by dimension.}

By \cref{def:dim-obligation}, the elimination data decomposes by dimension.  We trace the library references at each level.

\emph{Dimension~0.}
Point data $d_c : Y(c)$ references only $Y$ and the constructors of $X$---all from the current step $n+1$ and layer~$L_n$.  These are \textbf{depth-0/1 obligations}.

\emph{Dimension~1.}
Path data $d_p : \mathrm{transport}^Y(p, d_a) = d_b$ references:
(i) the transport function, which depends on how $Y$ varies along paths in $X$;
(ii) the point data $d_a, d_b$ from dimension~0; and
(iii) the path structure of library types that $Y$ references.
Since $Y$ may involve types from $L_n$, and their path structure was established at step $n$, these are \textbf{depth-1 obligations}.

\emph{Dimension~2.}
Surface data $d_s$ witnesses coherence of the path data.  The terms involve:
(i) the paths $d_p$ from dimension~1;
(ii) path composition and inversion in library types; and
(iii) the coherence of path composition---associators $\alpha : (p \cdot q) \cdot r = p \cdot (q \cdot r)$ and interchange laws.

The associator for paths $p$ from $L_n$ and $q$ from $L_{n-1}$ genuinely involves structure from both layers.  These are \textbf{depth-2 obligations}.

\medskip\noindent\textbf{Stage~2: Higher coherence is determined (Mac Lane--Lurie).}

Dimension-$k$ obligations for $k \geq 3$ involve coherence of the coherence data from dimension~2.  We appeal to:

\begin{quote}
\textbf{$\infty$-Groupoid Coherence Theorem}
(implicit in Lurie~\cite{lurie}, Prop.~1.2.5.1; see also Lumsdaine~\cite{lumsdaine}, van den Berg--Garner~\cite{vdberg-garner}).
\emph{Let $G$ be a weak $\infty$-groupoid presented by generators in dimensions $0$, $1$, and $2$.  The space of ways to extend this presentation to all higher dimensions---filling all higher coherence cells---is contractible.}
\end{quote}

In our setting, this means: once dimensions 0, 1, and 2 of the elimination data are fixed, all higher-dimensional coherence cells are uniquely determined.  The space of dimension-$k$ fillers (for $k \geq 3$) is a $(-1)$-type (contractible if inhabited).

Therefore, \textbf{dimension-$k$ obligations for $k \geq 3$ generate no independent conditions}: they are automatically satisfied and reference no new library structure beyond what dimensions 0--2 already reference.

\medskip\noindent\textbf{Stage~3: Depth-3 obligations reduce to depth-2.}

Suppose we have paths spanning three consecutive layers:
\begin{itemize}[nosep]
    \item $p$ from $L_n$ (introduced at step $n$),
    \item $q$ from $L_{n-1}$ (introduced at step $n-1$),
    \item $r$ from $L_{n-2}$ (introduced at step $n-2$).
\end{itemize}
The triple composite $p \cdot q \cdot r$ apparently involves all three layers.  The associator
\[
    \alpha_{p,q,r} : (p \cdot q) \cdot r = p \cdot (q \cdot r)
\]
decomposes into the pairwise interactions $(p, q)$ involving $L_n$ and $L_{n-1}$, and $(q, r)$ involving $L_{n-1}$ and $L_{n-2}$.

\emph{The key structural argument:} The coherence data for the pair $(q, r)$ was \emph{already computed and sealed when $L_{n-1}$ was introduced}.  At that time, $q$ was the new structure and $r$ was the preceding layer.  The resulting associators and higher coherences are now \emph{part of $L_{n-1}$'s exported interface}, available as established library facts.

The new obligations at step $n+1$ therefore need only cohere with the \emph{result} of the $(q, r)$-coherence (which lives in $L_{n-1}$'s interface), not with the raw data from $L_{n-2}$.

Formally: for any triple $(L_k, L_{k+1}, L_{k+2})$, an obligation $o$ referencing $L_k$ satisfies:
\begin{enumerate}[nosep]
    \item The coherence $\alpha_{q,r}$ between $L_k$ and $L_{k+1}$ is already in $\mathcal{O}^{(2)}(L_{k+1})$ (established).
    \item The obligation $o$ decomposes into: (a) the established $\alpha_{q,r}$ and (b) new coherence between $L_{k+1}$ and $L_{k+2}$.
\end{enumerate}
Therefore $o$ reduces at depth~3 in the sense of \cref{def:reduction}, and no irreducible obligation references $L_{n-2}$.
\end{proof}

\begin{remark}[The dimensional-to-temporal correspondence]
\label{rem:dim-temporal}
The proof relies on a correspondence between cell dimension and temporal layer depth:
\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Dimension} & \textbf{Content} & \textbf{Layer reference} \\
\midrule
0 & Point constructors of $X$ & Current step $n+1$ \\
1 & Path data \& transport & Interaction of $X$ with $L_n$ \\
2 & Coherence of paths & Interaction of $L_n$ with $L_{n-1}$ \\
$\geq 3$ & Higher coherence & Determined by dim.\ 0--2 \\
\bottomrule
\end{tabular}
\end{center}
The correspondence holds because $k$-dimensional coherence data involves $k$-fold compositions, and a $k$-fold composition of cells from the library can span at most $k$ layers.  Since the $\infty$-groupoid coherence theorem caps independent data at dimension~2, the temporal depth is capped at~2.
\end{remark}

\subsubsection{Lower Bound: $d \geq 2$}

\begin{theorem}[Coherence Lower Bound]
\label{thm:lower}
There exist cell presentations whose coherence obligations irreducibly span two layers.
\end{theorem}

\begin{proof}
\textbf{Example (Hopf fibration).}
Suppose the library contains:
\begin{itemize}[nosep]
    \item $L_{n-1}$: the circle $S^1 = \mathrm{HIT}\{\ \mathsf{base} : S^1,\ \mathsf{loop} : \mathsf{base} =_{S^1} \mathsf{base}\ \}$.
    \item $L_n$: the sphere $S^2 = \mathrm{HIT}\{\ \mathsf{base}_2 : S^2,\ \mathsf{surf} : \mathsf{refl} =_{\mathsf{base}_2 = \mathsf{base}_2} \mathsf{refl}\ \}$.
\end{itemize}

The Hopf fibration $h : S^3 \to S^2$ classifies a principal $S^1$-bundle over $S^2$.
Its construction requires a \emph{clutching function} $\gamma : S^1 \to \mathrm{Aut}(S^1)$, which encodes how the fiber $S^1$ twists over the equator of $S^2$.

The coherence conditions for the Hopf fibration's elimination principle involve:
\begin{enumerate}[nosep]
    \item The loop of $S^1$ (from $L_{n-1}$) acting on itself.
    \item The surface of $S^2$ (from $L_n$) constraining the total space.
    \item The compatibility of the clutching function with \emph{both} the $S^1$-action and the $S^2$-surface.
\end{enumerate}

Condition~(3) is a dimension-2 obligation that irreducibly references both $L_n$ (for $\mathsf{surf}$) and $L_{n-1}$ (for $\mathsf{loop}$).  It cannot be reformulated using only $L_n$, because the clutching function's domain is $S^1 \in L_{n-1}$.

Therefore $d \geq 2$. \qedhere
\end{proof}

\begin{corollary}[Intensional Coherence Window]
By \cref{thm:upper} ($d \leq 2$) and \cref{thm:lower} ($d \geq 2$), the Coherence Window of HoTT is exactly $d = 2$.
\end{corollary}

\begin{remark}[The saturation assumption]
\label{rem:saturation}
The PEN model assumes that each layer's elimination principle engages with \emph{all} available path structure---this is the \emph{saturation assumption}.  In HoTT, saturation follows from the universal property of eliminators: the recursor for $S^1$ must specify the image of \emph{every} constructor, including $\mathsf{loop}$, which forces engagement with the full path algebra of the target.  Under saturation, $|S(L_k)| = \Delta_k$: each layer exports exactly as many independent schemas as its integration cost.
\end{remark}

% ============================================
% SECTION 5: THE COMPLEXITY SCALING THEOREM
% ============================================
\section{The Complexity Scaling Theorem}
\label{sec:scaling}

We prove that Fibonacci-timed evolution is a mathematical necessity for Class~2 foundations under PEN.

\subsection{The Recurrence}

\begin{theorem}[Complexity Scaling]
\label{thm:scaling}
For a foundation with Coherence Window $d$, evolving under PEN with the saturation assumption (\cref{lem:recurrence}), the integration cost satisfies:
\begin{equation}
    \Delta_{n+1} = \sum_{j=0}^{d-1} \Delta_{n-j}
\end{equation}
\end{theorem}

\begin{proof}
\textbf{Step 1 (Window Constraint).}
The interface available for sealing $X_{n+1}$ is $I^{(d)}_n$.

\textbf{Step 2 (Disjoint Assembly).}
By \cref{def:interface}: $I^{(d)}_n = \biguplus_{j=0}^{d-1} S(L_{n-j})$.

\textbf{Step 3 (Conservation of Complexity).}
By \cref{lem:recurrence}, $\Delta_{n+1} = |I^{(d)}_n|$.
Since the union is disjoint:
\begin{equation}
    \Delta_{n+1} = \sum_{j=0}^{d-1} |S(L_{n-j})|
\end{equation}

\textbf{Step 4 (Recursive Substitution).}
By definition, $|S(L_k)| = \Delta_k$: each integration layer exports exactly as many schemas as its integration cost.
\end{proof}

\begin{corollary}
\label{cor:fibonacci}
For $d = 2$: $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$.
With $\Delta_1 = \Delta_2 = 1$ (Universe and Unit), this gives $\Delta_n = F_n$.
\end{corollary}

\subsection{The Realization Time Formula}

\begin{theorem}[The Golden Schedule]
\label{thm:schedule}
\begin{equation}
    \tau_n = \sum_{i=1}^{n} F_i = F_{n+2} - 1
\end{equation}
\end{theorem}

\begin{proof}
By \cref{def:tau}, $\tau_n = \sum_{i=1}^{n} \Delta_i = \sum_{i=1}^{n} F_i$.
The identity $\sum_{i=1}^{n} F_i = F_{n+2} - 1$ is standard.
\end{proof}

\subsection{Dynamical Consequences}

\subsubsection{Stagnation of Class 1 Systems}
\label{sec:stagnation}

For $d = 1$: $\Delta_{n+1} = \Delta_n$, so $\Delta_n = C$ (constant).

\textbf{Inflation:} $\Phi_n = 1$ for all $n$.
The bar reduces to $\mathrm{Bar}_n = \Omega_{n-1}$.

\textbf{Time:} $\tau_n = nC$ (linear).

\textbf{Efficiency Collapse.}
With constant integration costs, the Cumulative Baseline $\Omega_{n-1}$ converges to a finite limit as the library grows.
New candidates must clear a fixed efficiency threshold with diminishing returns on novelty.
The system does not halt, but its rate of producing genuinely novel structure decays to zero.
This is the \textbf{Stagnation Theorem}: Class~1 foundations are dynamically trapped in linear time.

\subsubsection{Acceleration of Class 2 Systems}

For $d = 2$: $\Delta_n = F_n \sim \varphi^n$.

\textbf{Inflation:} $\Phi_n = F_n / F_{n-1} \to \varphi$.
The convergence is \emph{from below} in the early game: $\Phi_3 = 2.00$, $\Phi_4 = 1.50$, $\Phi_5 = 1.67$, $\Phi_6 = 1.60$.
At $n = 4$, the dip to $1.50$ provides breathing room for the infrastructure step ($\rho_4 = 1.67$).

\textbf{Time:} $\tau_n = F_{n+2} - 1 \sim \varphi^{n+2}/\sqrt{5}$ (exponential).

\textbf{The Bar.}
$\mathrm{Bar}_n = \Phi_n \cdot \Omega_{n-1}$ grows steadily as $\Phi_n$ stabilizes near $\varphi$ and $\Omega_{n-1}$ increases with each realization.
Because $\Omega$ is a cumulative ratio, it is resistant to distortion by individual outliers.

\textbf{Unbounded Evolution.}
With $\Delta_n$ growing exponentially and the library expanding at each step, the Combinatorial Novelty (\cref{thm:exponentiality}) grows superlinearly.
Efficiency $\rho_n$ outpaces the bar, which is bounded by the cumulative average.
The system enters a state of accelerating complexity.

\paragraph{The Infrastructure Correspondence.}
The viability of the Genesis Sequence rests on a precise correspondence between two manifestations of the Fibonacci sequence:
\begin{enumerate}[nosep]
    \item The \emph{structural} oscillation of $\Phi_n = F_n/F_{n-1}$ around $\varphi$, modulating the bar.
    \item The \emph{evolutionary} alternation between infrastructure realizations (low $\rho$, high enabling power) and geometric ones (high $\rho$, exploiting infrastructure).
\end{enumerate}
The same recurrence governs both.
This resolves the paradox of why intensional foundations appear ``more fertile'' than extensional ones: it is a structural necessity for sustaining exponential growth.

% ============================================
% SECTION 6: INDUCTIVE EXPONENTIALITY
% ============================================
\section{The Combinatorial Novelty Theorem}
\label{sec:exponentiality}

The Complexity Scaling Theorem established that integration costs grow as $\Delta_n \sim \varphi^n$.
If novelty scaled only linearly with cost ($\nu \propto \Delta$), efficiency would converge to a constant while the bar rises, causing collapse.
We prove that in constructive type theory, novelty scales \emph{superlinearly}: exponentially for ordinary inductive types (OITs), and at least linearly---with multiplicative amplification under synthesis---for higher inductive types (HITs).

\subsection{The Interface as a Signature}

\begin{definition}[Interface-Constructor Correspondence]
\label{def:signature}
Let $X$ be a structure saturating an interface of size $\Delta$.
In intensional type theory, this interface constitutes the \emph{signature} of $X$ as an inductive type:
each schema corresponds to a constructor (point, path, surface), and $\Delta$ counts the orthogonal generators.
\end{definition}

\begin{definition}[Point-Constructor Count]
\label{def:point-constructors}
For an inductive type $X$ with constructor list $c_1, \ldots, c_\Delta$, let $\Delta_0 \leq \Delta$ denote the number of \emph{point constructors}---those whose target is $X$ itself (as opposed to path or higher constructors whose target is an identity type).
An \emph{ordinary inductive type} (OIT) has $\Delta_0 = \Delta$; a \emph{higher inductive type} (HIT) has $\Delta_0 < \Delta$.
\end{definition}

\subsection{Combinatorial Scaling}

\begin{theorem}[OIT Exponentiality]
\label{thm:oit-exponentiality}
Let $X$ be an ordinary inductive type with $\Delta_0$ point constructors (and no path constructors).
Let the library contain a testing type $\mathbf{2}$ (Boolean).
The number of distinct functions $f : X \to \mathbf{2}$ definable with $O(\Delta_0)$ effort is $2^{\Delta_0}$.
\end{theorem}

\begin{proof}
Since $X$ is an OIT, every constructor is a point constructor and the eliminator into any type is unconstrained: a function $f : X \to \mathbf{2}$ requires one computation rule per constructor, with no coherence conditions.
\begin{equation}
    f(x) := \mathbf{case}\ x\ \mathbf{of}\ \{c_1 \mapsto b_1;\; \ldots;\; c_{\Delta_0} \mapsto b_{\Delta_0}\}
\end{equation}
Each of the $\Delta_0$ branches independently chooses $b_i \in \{\mathrm{true}, \mathrm{false}\}$; disjointness of constructors ensures semantic distinctness.
Cost: $\kappa = 1 + \Delta_0$.  Count: $2^{\Delta_0}$.
\end{proof}

\begin{remark}[HIT Constraints on Boolean Predicates]
\label{rem:hit-constraints}
For a higher inductive type $X$, path constructors impose coherence: a function $f : X \to \mathbf{2}$ must map path-connected points to the same value (since $\mathbf{2}$ is a set).
The number of such functions equals $2^{|\pi_0(X)|}$, the number of connected components.
For example, $S^1$ ($\Delta = 2$: one point, one loop) has $\pi_0 \cong 1$, giving only $2^1 = 2$ maps to~$\mathbf{2}$, not $2^2 = 4$.
The torus $T^2$ ($\Delta = 4$) is connected, giving $2^1 = 2$ maps to~$\mathbf{2}$, not $2^4 = 16$.
Thus the OIT exponentiality result does not extend to HITs when the codomain is a set.
\end{remark}

\begin{theorem}[Combinatorial Novelty]
\label{thm:exponentiality}
Let $X$ be a structure with $\Delta_0$ point constructors, realized into a library $\mathcal{B}$ containing $|\mathcal{B}|$ prior types.
Define the \emph{novelty} $\nu(X \mid \mathcal{B})$ as the count of newly enabled constructions (including eliminations into all library types and composite operations).
Then:
\begin{enumerate}[nosep]
    \item \textbf{OIT base case:} If $X$ is an OIT, $\nu(X \mid \mathcal{B}) \geq 2^{\Delta_0}$ (from maps to $\mathbf{2}$ alone).
    \item \textbf{Library interaction:} Each prior type $T \in \mathcal{B}$ contributes at least $\Delta_0$ new maps $X \to T$, so $\nu(X \mid \mathcal{B}) \geq \Delta_0 \cdot |\mathcal{B}|$.
    \item \textbf{Synthesis:} Forming composites $X \times Y$, $X \to Y$, fibrations over $X$ multiplies the novelty of $X$ by that of $Y$.
\end{enumerate}
In particular, for the Genesis Sequence where $\Delta_0 \geq 1$ and $|\mathcal{B}|$ grows with $n$, the ratio $\rho_n = \nu_n / \kappa_n$ satisfies $\rho_n \to \infty$.
\end{theorem}

\begin{proof}
\textbf{Step 1 (OIT base).}
For ordinary inductive types, the OIT Exponentiality theorem gives $\nu \geq 2^{\Delta_0}$ from maps to $\mathbf{2}$ alone.

\textbf{Step 2 (Library interactions).}
For any type $X$ (OIT or HIT), eliminating into each library type $T \in \mathcal{B}$ produces at least $\Delta_0$ independent maps (one per point constructor), contributing $\Delta_0 \cdot |\mathcal{B}|$ to novelty.
For HITs, dependent elimination into type families over $X$ recovers degrees of freedom lost in the non-dependent case: the eliminator of $T^2$ into type families parameterized by the library yields constructions sensitive to all four constructors.

\textbf{Step 3 (Synthesis multiplicativity).}
When two types $X, Y$ are both in $\mathcal{B}$, their product $X \times Y$, function type $X \to Y$, and fibrations produce novelty multiplicative in $\nu(X)$ and $\nu(Y)$.

\textbf{Step 4 (Divergence).}
The bar $\mathrm{Bar}_n = \Phi_n \cdot \Omega_{n-1}$ grows sub-linearly: $\Omega$ is a cumulative average of past efficiencies, and $\Phi_n \to \varphi$.
Meanwhile, $\nu_n \geq \Delta_0 \cdot |\mathcal{B}_n|$ grows at least as $\Delta_0 \cdot n$, and $\kappa_n$ is bounded by $O(\Delta_n)$.
Since $\Delta_0 \geq 1$ and $|\mathcal{B}_n| = n$, efficiency $\rho_n \geq n / O(\Delta_n)$ grows without bound once library interactions and synthesis amplification are included.
Hence $\rho_n \to \infty$.
\end{proof}

\begin{remark}
This explains why Higher Inductive Types dominate despite their constrained Boolean predicates.
The torus $T^2$ has interface $\Delta = 4$ (point, two loops, surface) but is connected, so it admits only $2$ maps to~$\mathbf{2}$.
However, its eliminator into \emph{type families} parameterized by the library yields constructions sensitive to all four constructors: dependent elimination, transport along loops, and fibrations over $T^2$ contribute novelty proportional to $\Delta_0 \cdot |\mathcal{B}|$.
HIT novelty arises from dependent elimination and library cross-interactions, not from maps to Bool.
\end{remark}

\subsection{Asymptotic Escape Velocity}

\begin{theorem}[Divergence of Efficiency]
\label{thm:divergence}
In a Class~2 foundation, $\lim_{n \to \infty} \rho_n = \infty$.
\end{theorem}

\begin{proof}
\textbf{Step 1 (Sub-linear bar).}
The bar $\mathrm{Bar}_n = \Phi_n \cdot \Omega_{n-1}$ is the product of structural inflation ($\Phi_n \to \varphi$, a constant) and the cumulative average efficiency $\Omega_{n-1}$.
Because $\Omega$ is an average, it grows strictly slower than $\rho_n$ itself.

\textbf{Step 2 (At-least-linear novelty).}
By \cref{thm:exponentiality}, $\nu_n \geq \Delta_0 \cdot |\mathcal{B}_n|$.
Since each realization adds to the library, $|\mathcal{B}_n| = n$, and $\Delta_0 \geq 1$ for every realization, so $\nu_n$ grows at least linearly in~$n$.

\textbf{Step 3 (Synthesis amplification).}
Composite constructions (products, function types, fibrations) contribute novelty multiplicative in the novelties of their components, reinforcing the superlinear growth.

\textbf{Step 4 (Divergence).}
\begin{equation}
    \rho_n = \frac{\nu_n}{\kappa_n} \geq \frac{\Delta_0 \cdot n}{O(\Delta_n)}
\end{equation}
The numerator grows at least linearly; $\Omega_{n-1}$ (a cumulative average) grows sub-linearly.
Hence $\rho_n$ eventually exceeds $\mathrm{Bar}_n$, and since $\rho_n \to \infty$, the system never stagnates.
\end{proof}

% ============================================
% SECTION 7: COMPUTATIONAL VERIFICATION
% ============================================
\section{Computational Verification}
\label{sec:verification}

We verify the theoretical predictions with two independent implementations.
The companion paper~\cite{pen-genesis} presents the full computational reconstruction with detailed methodology; here we summarize the key results.

\subsection{The Haskell Engine}

A $\sim$3{,}000-line Haskell engine%
\footnote{Source code: \texttt{engine/}, 17 modules.
Build: \texttt{cd engine \&\& cabal build}.
Run: \texttt{cabal run pen-engine}.}
implements the five PEN axioms as a synthesis loop.
Starting from an empty library, it generates candidates from nine structural categories---Foundations, Formers, HITs, Suspensions, Maps, Algebras, Modals, Axioms, and Synthesis types---each gated by prerequisites (e.g., suspensions require loopy types in the library; the Hopf fibration requires $S^1$, $S^2$, $S^3$).

Novelty for HITs and suspensions is computed by \emph{proof-rank clustering}, a domain-independent algorithm:
enumerate newly inhabited types at expression depth~$\leq 1$, abstract each type to a schema (replacing specific names with generic variables), filter trivial schemas, and count the remaining independent clusters.
For maps, modals, axioms, and synthesis candidates, $\nu$ is computed by component-based structural formulas.
The synthesis candidate (DCT) uses the Lattice Tensor Product: $\nu = 14 \times 11 - 4 = 150$, gated on Cohesion being present in the library.
See~\cite{pen-genesis} for the full algorithm and architecture.

\paragraph{Results.}
The engine discovers all 15 Genesis structures in the correct order.
Values of $\nu$ match the table exactly for 12 of 15 structures and lie within $\pm 15\%$ for the remaining three ($S^3$, Connections, Hilbert).
These variations arise from the depth-1 enumeration window, which does not fully capture deep homotopy-theoretic structure (e.g., $\pi_3(S^3) \cong \Z$).
In all cases the structure clears its bar, and the ordering is preserved.

The engine's bar values differ slightly from the table because $S^3$ is discovered as a suspension ($\kappa = 3$) rather than as an SU(2)-equipped type ($\kappa = 5$).
Both interpretations produce the same sequence; the question of whether $\kappa$ measures the bare type definition or the equipped type remains open.

Four independent cross-validation modes (paper replay, capability computation, capability replay, genuine synthesis) all produce consistent results; see~\cite{pen-genesis} for details.

\subsection{Coherence Window Stress-Testing}

The engine accepts a \texttt{--window d} flag that parameterizes the Coherence Window.
Internally, the Fibonacci sequence is replaced by the $d$-bonacci sequence:
\begin{equation}
    \Delta^{(d)}_{n+1} = \sum_{j=0}^{d-1} \Delta^{(d)}_{n-j}, \qquad \Delta^{(d)}_1 = \cdots = \Delta^{(d)}_d = 1.
\end{equation}
For $d = 1$ (constant sequence), $d = 2$ (Fibonacci), and $d = 3$ (tribonacci).
The window function \texttt{windowAtoms} takes the last $d$ library entries instead of hardcoded $d=2$.

\paragraph{Results.}
Running with $d = 1$ produces a sequence that stagnates after 4--5 structures: constant $\Delta = 1$ means the bar never rises significantly, but novelty remains bounded, and the system enters a regime of diminishing returns.
Running with $d = 2$ reproduces the known Genesis Sequence of 15 structures.
Running with $d = 3$ produces a sequence with tribonacci costs $\{1, 1, 2, 4, 7, 13, \ldots\}$; the faster-growing costs cause the system to stall earlier as $\kappa$ outpaces the horizon.
This provides computational evidence that $d = 2$ is the unique value supporting sustained, non-trivial evolution.

\subsection{Cubical Agda Mechanization}

The Complexity Scaling Theorem (\cref{thm:scaling}) is proved in Cubical Agda~\cite{cubical-agda}%
\footnote{Source code: \texttt{agda/}.}:
for $d = 2$ and the saturation assumption, $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$.
The proof is machine-checked and covers:
\begin{itemize}[nosep]
    \item Initial conditions: $\Delta_1 = \Delta_2 = 1$.
    \item The Fibonacci recurrence: $\Delta_{n+1} = \Delta_n + \Delta_{n-1}$.
    \item The cumulative sum identity: $\tau_n = F_{n+2} - 1$.
    \item Convergence: $\Phi_n \to \varphi$.
\end{itemize}

\paragraph{Coherence Obligation Experiments.}
Cubical Agda experiment files (\texttt{agda/Experiments/}) trace the coherence obligations for $S^1$, $S^2$, $T^2$, and the Hopf fibration.
For each HIT, every elimination goal presented by Agda is classified by the library layers it references.
In all cases: all obligations reference at most 2 layers, at least one obligation genuinely references 2 layers, and no obligation references 3 layers.
An active attempt to construct a depth-3 counterexample (a chain $A \to B \to C \to D$ requiring $D$'s coherence to irreducibly reference $A$) confirms the reducibility argument of \cref{thm:upper}: the coherence between $A$ and $B$ was established when $B$ was sealed, so $D$'s obligations decompose into depth-2 pieces.

A $\kappa$-oracle using Agda's reflection API (counting constructors of type definitions) is partially implemented.
The $\nu$-measure and selection loop are not yet mechanized.
The Haskell engine serves as the fast explorer; Agda serves as the trusted checker for the foundational theorems.

% ============================================
% SECTION 8: CONCLUSION
% ============================================
\section{Conclusion}
\label{sec:conclusion}

We have shown that the choice of mathematical foundation is a choice of Coherence Window.

\begin{itemize}[nosep]
    \item \textbf{Class 1 (Extensional), $d = 1$:}
    Constant integration costs.
    Bounded novelty ($2^{O(1)}$).
    Linear time, asymptotic stagnation.

    \item \textbf{Class 2 (Intensional), $d = 2$:}
    Fibonacci integration costs ($\Delta_{n+1} = \Delta_n + \Delta_{n-1}$).
    Superlinearly growing novelty (exponential for OITs; library-amplified for HITs; multiplicative under synthesis).
    Exponential time, unbounded acceleration.
\end{itemize}

The Golden Ratio of mathematical evolution is the dominant eigenvalue of a memory system that looks back exactly two steps.
Intensional type theory is not merely a logical alternative to extensional foundations; it is the unique substrate that sustains exponentially growing structural complexity.

The companion paper~\cite{pen-genesis} exhibits the full Genesis Sequence produced by these axioms---15 structures from dependent types to the Dynamical Cohesive Topos~\cite{nakano,schreiber}---and verifies it with a Haskell engine that discovers all 15 structures from unconstrained search.
The complete engine source code ($\sim$3{,}000 lines of Haskell) and Cubical Agda proofs are available as supplementary material.

% ============================================
% REFERENCES
% ============================================
\begin{thebibliography}{9}

\bibitem{pen-genesis}
H.~Lande.
The Genesis Sequence: A Computational Reconstruction of the Mathematical Hierarchy.
2026.

\bibitem{hott}
Univalent Foundations Program.
\textit{Homotopy Type Theory: Univalent Foundations of Mathematics}.
Institute for Advanced Study, 2013.

\bibitem{cubical}
C.~Cohen, T.~Coquand, S.~Huber, A.~M\"ortberg.
Cubical Type Theory: a constructive interpretation of the univalence axiom.
\textit{TYPES 2015}, 2015.

\bibitem{schreiber}
U.~Schreiber.
Differential Cohomology in a Cohesive Infinity-Topos.
arXiv:1310.7930, 2013.

\bibitem{lawvere}
F.~W.~Lawvere.
Axiomatic Cohesion.
\textit{Theory and Applications of Categories}, 19(3), 2007.

\bibitem{nakano}
H.~Nakano.
A Modality for Recursion.
\textit{Proceedings of LICS}, 2000.

\bibitem{cubical-agda}
A.~Vezzosi, A.~M\"ortberg, A.~Abel.
Cubical Agda: A Dependently Typed Programming Language with Univalence and Higher Inductive Types.
\textit{ICFP}, 2019.

\bibitem{lurie}
J.~Lurie.
\textit{Higher Topos Theory}.
Annals of Mathematics Studies, vol.~170, Princeton University Press, 2009.

\bibitem{lumsdaine}
P.~L.~Lumsdaine.
Weak $\omega$-Categories from Intensional Type Theory.
\textit{Typed Lambda Calculi and Applications (TLCA)}, LNCS 6690, pp.~172--187, 2010.

\bibitem{vdberg-garner}
B.~van den Berg, R.~Garner.
Types are Weak $\omega$-Groupoids.
\textit{Proceedings of the London Mathematical Society}, 102(2):370--394, 2011.

\bibitem{maclane-coherence}
S.~Mac Lane.
Natural Associativity and Commutativity.
\textit{Rice University Studies}, 49(4):28--46, 1963.

\bibitem{stasheff}
J.~D.~Stasheff.
Homotopy Associativity of H-Spaces~I, II.
\textit{Transactions of the American Mathematical Society}, 108(2):275--312, 1963.

\bibitem{kraus-vonraumer}
N.~Kraus, J.~von Raumer.
Coherence via Well-Foundedness: Taming Set-Quotients in Homotopy Type Theory.
\textit{Proceedings of LICS}, 2019.

\end{thebibliography}

\end{document}
